'''
readitlaterlist.com
'''
__license__   = 'GPL v3'
__copyright__ = '''
2010, Darko Miletic <darko.miletic at gmail.com>
2011, Przemyslaw Kryger <pkryger at gmail.com>
2011, Keith Callenberg <keithcallenberg@gmail.com>
2012, tBunnyMan <Wag That Tail At Me dot com>
2012, Alayn Gortazar <zutoin at gmail dot com>
'''

from contextlib import closing
from calibre.web.feeds.news import BasicNewsRecipe
from calibre.ebooks.BeautifulSoup import Tag
import json
import urllib
import urllib2

class Readitlater(BasicNewsRecipe):
    title                 = 'Read It Later'
    __author__            = 'Darko Miletic, Przemyslaw Kryger, Keith Callenberg, tBunnyMan, Alayn Gortazar'
    description           = '''Personalized news feeds. Go to readitlaterlist.com to
                               setup up your news. Fill in your account
                               username, and optionally you can add your password.'''
    publisher             = 'readitlaterlist.com'
    category              = 'news, custom'
    oldest_article        = 7
    max_articles_per_feed = 50
    minimum_articles      = 1
    no_stylesheets        = True
    use_embedded_content  = False
    needs_subscription    = True
    KEY                   = '8e0p5f19A74emL3a47goP87m69d4VF8b'
    INDEX                 = 'https://readitlaterlist.com/'
    LOGIN                 = INDEX + u'/l'

    articles           = []
    
    feeds = [(u'Unread articles' , INDEX)]

    def get_browser(self):
        br = BasicNewsRecipe.get_browser()
        if self.username is not None:
            br.open(self.LOGIN)
            br.select_form(nr=0)
            br['feed_id'] = self.username
            if self.password is not None:
                br['password'] = self.password
            br.submit()
        return br



    def parse_index(self):
        index = self.INDEX + 'v2/get?'
        index += 'apikey=' + self.KEY
        if self.username is not None:
            index += '&username=' + self.username 
            if self.password is not None:
                index += '&password=' + self.password 
        index += '&state=unread'
        index += '&count=' + str(self.max_articles_per_feed) 

        open_func = getattr(self.browser, 'open_novisit', self.browser.open)
        with closing(open_func(index)) as f:
            results = f.read()
        if not results:
            raise RuntimeError('Could not fetch index!')

        json_obj = json.loads(results)
        
        if len(json_obj['list']) >= self.minimum_articles:
            for item in json_obj['list'].iteritems():
                # TODO: This URL should be modified by it's corresponding API call in a future. 
                #       Actually is not possible to get the Article View potential throught an API call (12/04/2012)
                dataurl = self.INDEX + "a/x/getArticle.php?itemId=" + item[1]['item_id']
                self.articles.append({
                                 'title':item[1]['title'],
                                 'date':item[1]['time_added'],
                                 'url':dataurl,
                                 'description':item[1]['item_id'],
                                 'real_url':item[1]['url']
                            })
        else:
            raise Exception("Not enough articles in RIL! Change minimum_articles or add more.")

        return [('Unread', self.articles)]

    def preprocess_raw_html(self, raw_html, url):
        # get article and image urls from json object
        json_obj = json.loads(raw_html)
        self.images = {}
        for image in json_obj['article']['images']:
            self.images[image] = json_obj['article']['images'][image]['src']
        title = '<h1>{title}</h1>'.format(title=json_obj['article']['title']) 
        link = '<p>Original: <a href="{url}">{url}</a></p>'.format(url=json_obj['article']['resolvedUrl'])
        return link + title + json_obj['article']['article'] + '<hr />'

    def preprocess_html(self, soup):
        # Insert images on RIL_IMG_# divs
        for key, url in self.images.iteritems():
            imgtag = Tag(soup, 'img')
            imgtag['src'] = url
            div = soup.find('div', attrs={'id':'RIL_IMG_' + key})
            div.insert(0, imgtag)
        return soup

    def cleanup(self):
        # From a list of urls, create a human-readable JSON string
        # suitable for passing to the ReadItLater SEND::READ method.
    
        #self.markAsRead(self.createMarkList(self.articles))
        return 

    def createMarkList(self, articles):
        urls = []
        for article in self.articles:
            urls.append(article['real_url'])
        items = ['"%d": {"url": "%s"}' % (n,u) for n,u in enumerate(urls)]
        s = '{\n %s\n}' % (',\n '.join(items),)
        return s

    def markAsRead(self, markList):
        url = self.INDEX + 'v2/send'
        values = {
            'username' : self.username,
            'password' : self.password,
            'apikey' : self.KEY,
            'read' : markList
            }
        data = urllib.urlencode(values)
    
        try:
            print 'Calling ReadItLater API...'
            request = urllib2.Request(url,data)
            response = urllib2.urlopen(request)
            the_page = response.read()
            print 'response =', response.code
        except urllib2.HTTPError as e:
            print 'The server could not fulfill the request: ', e
        except urllib2.URLError as e:
            print 'The call to ReadItLater API failed:', e
