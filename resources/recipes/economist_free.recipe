from calibre.web.feeds.news import BasicNewsRecipe
import time
from datetime import datetime
from lxml import html

class Economist(BasicNewsRecipe):

    title = 'The Economist (free)'
    language = 'en'

    __author__ = "Kovid Goyal"
    description = ('Global news and current affairs from a European perspective.'
            ' Much slower than the subscription based version.')

    oldest_article = 6.5
    cover_url = 'http://www.economist.com/images/covers/currentcovereu_large.jpg'
    remove_tags = [dict(name=['script', 'noscript', 'title'])]
    remove_tags_before = dict(name=lambda tag: tag.name=='title' and tag.parent.name=='body')

    def parse_index(self):
        from calibre.web.feeds.feedparser import parse
        raw = self.index_to_soup(
                'http://feeds.feedburner.com/economist/full_print_edition',
                raw=True)
        entries = parse(raw).entries
        feeds = {}
        for i, item in enumerate(entries):
            from calibre.web.feeds import Article
            published   = time.gmtime(item.get('timestamp', time.time()))
            title       = item.get('title', _('Untitled article'))
            link        = item.get('link', None)
            description = item.get('description', '')
            author      = item.get('author', '')

            try:
                feedtitle, link = self.process_eco_feed_article(link)
                self.log('Found print version for article:', title)
            except:
                self.log.exception('Failed to process article:', title)
                continue

            a = Article(i, title, link, author, description, published, '')
            delta = datetime.utcnow() - a.utctime
            if delta.days*24*3600 + delta.seconds > 24*3600*self.oldest_article:
                self.log.debug('Skipping article %s (%s) from feed %s as it is too old.'%(title, a.localtime.strftime('%a, %d %b, %Y %H:%M'), title))
                continue


            article = dict(title=a.title, description=a.text_summary,
                date=time.strftime(self.timefmt, a.date), author=a.author, url=a.url)
            if feedtitle not in feeds:
                feeds[feedtitle] = []
            feeds[feedtitle].append(article)
        return [(t, a) for t, a in feeds.items()]

    def process_eco_feed_article(self, url):
        ret = self.browser.open(url)
        raw = ret.read()
        url = self.browser.geturl().replace('displaystory', 'PrinterFriendly').strip()
        root = html.fromstring(raw)
        matches = root.xpath('//*[@class = "article-section"]')
        feedtitle = 'Miscellaneous'
        if matches:
            feedtitle = html.tostring(matches[0], method='text',
                    encoding=unicode)
        return feedtitle, url


